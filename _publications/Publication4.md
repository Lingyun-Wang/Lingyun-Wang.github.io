---
title: "Sub2Full: split spectrum to boost optical coherence tomography despeckling without clean data"
collection: publications
permalink: /publications/Publication4
excerpt: 'Optical coherence tomography (OCT) suffers from speckle noise, causing the deterioration of image quality, especially in high-resolution modalities such as visible light OCT (vis-OCT). Here, we proposed an innovative self-supervised strategy called Sub2Full (S2F) for OCT despeckling without clean data. This approach works by acquiring two repeated B-scans, splitting the spectrum of the first repeat as a low-resolution input, and utilizing the full spectrum of the second repeat as the high-resolution target. The proposed method was validated on vis-OCT retinal images visualizing sublaminar structures in the outer retina and demonstrated superior performance over state-of-the-art Noise2Noise (N2N) and Noise2Void (N2V) schemes.'
date: 2024-05-27
venue: 'Optics Letters'
paperurl: ''
citation: 'Wang, L., Sahel, J., Pi, S., Sub2Full: split spectrum to boost optical coherence tomography despeckling without clean data. Optics Letters. 2024. https://doi.org/10.1364/OL.518906'
---

**Abstract**  
Optical coherence tomography (OCT) suffers from speckle noise, causing the deterioration of image quality, especially in high-resolution modalities such as visible light OCT (vis-OCT). Here, we proposed an innovative self-supervised strategy called Sub2Full (S2F) for OCT despeckling without clean data. This approach works by acquiring two repeated B-scans, splitting the spectrum of the first repeat as a low-resolution input, and utilizing the full spectrum of the second repeat as the high-resolution target. The proposed method was validated on vis-OCT retinal images visualizing sublaminar structures in the outer retina and demonstrated superior performance over state-of-the-art Noise2Noise (N2N) and Noise2Void (N2V) schemes.
![Pub4Image1](http://Lingyun-Wang.github.io/images/Pub4Img1.png)  
Figure 1. The pipeline of the proposed Sub2Full strategy.  

[Download paper here](http://Lingyun-Wang.github.io/files/paper4.pdf)
